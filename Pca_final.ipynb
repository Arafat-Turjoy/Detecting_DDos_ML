{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "x[:,5] = le.fit_transform(x[:,5])\n",
    "x[:,7] = le.fit_transform(x[:,7])\n",
    "x[:,12] = le.fit_transform(x[:,12])\n",
    "x[:,13] = le.fit_transform(x[:,13])\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/turjoy/anaconda3/envs/Arafat/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x= scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "     x, y, test_size = 0.2, random_state = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37159928 0.24393848]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "  \n",
    "pca = PCA(copy=True, iterated_power= 'auto', n_components=2, random_state= 100,\n",
    "  svd_solver='randomized', tol=0.5, whiten=True) \n",
    "  \n",
    "x_train_pca = pca.fit_transform(x_train) \n",
    "x_test_pca = pca.transform(x_test) \n",
    "  \n",
    "explained_variance = pca.explained_variance_ratio_ \n",
    "print (explained_variance)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.recurrent import LSTM \n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nn = np_utils.to_categorical(y_train, 5)\n",
    "y_test_nn = np_utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_nn = np.reshape(x_train_pca, (x_train_pca.shape[0], 1, x_train_pca.shape[1]))\n",
    "x_test_nn = np.reshape(x_test_pca, (x_test_pca.shape[0], 1, x_test_pca.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 1, 32)             1120      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,365\n",
      "Trainable params: 3,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(32, input_shape = (1,2), return_sequences=True, kernel_initializer='uniform', activation='tanh'))\n",
    "rnn_model.add(Dropout(0.4))\n",
    "rnn_model.add(SimpleRNN(32,activation='tanh'))\n",
    "rnn_model.add(Dropout(0.4))\n",
    "rnn_model.add(Dense(units = 5,activation='softmax'))\n",
    "rnn_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., amsgrad=False), metrics=['accuracy'])\n",
    "print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 838860 samples, validate on 209715 samples\n",
      "Epoch 1/5\n",
      "838860/838860 [==============================] - 116s 138us/step - loss: 0.3739 - acc: 0.8968 - val_loss: 0.2231 - val_acc: 0.8957\n",
      "Epoch 2/5\n",
      "838860/838860 [==============================] - 109s 129us/step - loss: 0.1879 - acc: 0.9582 - val_loss: 0.1356 - val_acc: 0.9740\n",
      "Epoch 3/5\n",
      "838860/838860 [==============================] - 109s 130us/step - loss: 0.1539 - acc: 0.9707 - val_loss: 0.1274 - val_acc: 0.9737\n",
      "Epoch 4/5\n",
      "838860/838860 [==============================] - 107s 128us/step - loss: 0.1445 - acc: 0.9720 - val_loss: 0.1243 - val_acc: 0.9740\n",
      "Epoch 5/5\n",
      "838860/838860 [==============================] - 107s 128us/step - loss: 0.1415 - acc: 0.9721 - val_loss: 0.1240 - val_acc: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd13a45f6a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(x_train_nn, y_train_nn, validation_data = (x_test_nn, y_test_nn), epochs = 5, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209715/209715 [==============================] - 13s 62us/step\n",
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.12397649821710328, 0.9747895954052749]\n"
     ]
    }
   ],
   "source": [
    "metrics = rnn_model.evaluate(x_test_nn, y_test_nn, verbose=1)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0     48      0      0    332]\n",
      " [     0 187803      0      0     45]\n",
      " [     0    607      0      0      0]\n",
      " [     0    846      0      0    397]\n",
      " [     0   3012      0      0  16625]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_expect = y_test_nn\n",
    "y_expect = np.argmax(y_expect, axis=1)\n",
    "y_predict = rnn_model.predict(x_test_nn)\n",
    "y_predict = np.argmax(y_predict, axis=1)\n",
    "cm = confusion_matrix(y_expect, y_predict)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       380\n",
      "           1       0.98      1.00      0.99    187848\n",
      "           2       0.00      0.00      0.00       607\n",
      "           3       0.00      0.00      0.00      1243\n",
      "           4       0.96      0.85      0.90     19637\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    209715\n",
      "   macro avg       0.39      0.37      0.38    209715\n",
      "weighted avg       0.96      0.97      0.97    209715\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/turjoy/anaconda3/envs/Arafat/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_expect,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(rnn_model,show_shapes=True,rankdir='TB',to_file='pcaRnn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lstm = np_utils.to_categorical(y_train, 5)\n",
    "y_test_lstm = np_utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm = np.reshape(x_train_pca, (x_train_pca.shape[0], 1, x_train_pca.shape[1]))\n",
    "x_test_lstm = np.reshape(x_test_pca, (x_test_pca.shape[0], 1, x_test_pca.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 30)             3960      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 30)             7320      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 155       \n",
      "=================================================================\n",
      "Total params: 18,755\n",
      "Trainable params: 18,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_dim = 2\n",
    "timesteps = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(30, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 30\n",
    "model.add(LSTM(30, return_sequences=True))  # returns a sequence of vectors of dimension 30\n",
    "model.add(LSTM(30))  # return a single vector of dimension 30\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 838860 samples, validate on 209715 samples\n",
      "Epoch 1/5\n",
      "838860/838860 [==============================] - 322s 384us/step - loss: 0.1382 - acc: 0.9701 - val_loss: 0.1160 - val_acc: 0.9745\n",
      "Epoch 2/5\n",
      "838860/838860 [==============================] - 332s 396us/step - loss: 0.1170 - acc: 0.9743 - val_loss: 0.1135 - val_acc: 0.9750\n",
      "Epoch 3/5\n",
      "838860/838860 [==============================] - 309s 368us/step - loss: 0.1156 - acc: 0.9747 - val_loss: 0.1131 - val_acc: 0.9758\n",
      "Epoch 4/5\n",
      "838860/838860 [==============================] - 299s 356us/step - loss: 0.1157 - acc: 0.9756 - val_loss: 0.1125 - val_acc: 0.9769\n",
      "Epoch 5/5\n",
      "838860/838860 [==============================] - 296s 352us/step - loss: 0.1149 - acc: 0.9764 - val_loss: 0.1147 - val_acc: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd0cca376d8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_lstm, y_train_lstm,validation_data = (x_test_lstm, y_test_lstm), batch_size = 50, epochs = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209715/209715 [==============================] - 21s 98us/step\n",
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.11466470518382871, 0.975643134732457]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test_lstm, y_test_lstm, verbose=1)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0     15     15      0    350]\n",
      " [     0 187043    599      0    206]\n",
      " [     0    289    317      0      1]\n",
      " [     2    811     25      3    402]\n",
      " [     0   2364     29      0  17244]]\n"
     ]
    }
   ],
   "source": [
    "y_expect_ls = y_test_lstm\n",
    "y_expect_ls = np.argmax(y_expect_ls, axis=1)\n",
    "y_predict_ls = model.predict(x_test_lstm)\n",
    "y_predict_ls = np.argmax(y_predict_ls, axis=1)\n",
    "cm = confusion_matrix(y_expect_ls, y_predict_ls)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       380\n",
      "           1       0.98      1.00      0.99    187848\n",
      "           2       0.32      0.52      0.40       607\n",
      "           3       1.00      0.00      0.00      1243\n",
      "           4       0.95      0.88      0.91     19637\n",
      "\n",
      "   micro avg       0.98      0.98      0.98    209715\n",
      "   macro avg       0.65      0.48      0.46    209715\n",
      "weighted avg       0.97      0.98      0.97    209715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_expect_ls,y_predict_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model,show_shapes=True,rankdir='TB',to_file='PcaLstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
